import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import RFE, SelectKBest, f_regression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Load the dataset
df = pd.read_csv('PEP.csv')

# Convert 'Date' to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Create visualizations
plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Close'], label='Close Price')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('Close Price Over Time')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Volume'], label='Volume', color='orange')
plt.xlabel('Date')
plt.ylabel('Volume')
plt.title('Volume Over Time')
plt.legend()
plt.grid(True)
plt.show()

# Create binary classification target: 1 if price increased, 0 if decreased
df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)

# Drop rows with missing values due to shift
df.dropna(inplace=True)

# Select features and target
X = df[['Open', 'High', 'Low', 'Volume']]
y = df['Target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Feature Selection

# 1. Recursive Feature Elimination (RFE) with Decision Tree
rfe_selector = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=2, step=1)
X_train_rfe = rfe_selector.fit_transform(X_train_scaled, y_train)
X_test_rfe = rfe_selector.transform(X_test_scaled)

# 2. SelectKBest (using ANOVA F-statistic)
select_kbest = SelectKBest(score_func=f_regression, k=2)
X_train_kbest = select_kbest.fit_transform(X_train_scaled, y_train)
X_test_kbest = select_kbest.transform(X_test_scaled)

# Classification Algorithms

# 1. Decision Tree
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train_scaled, y_train)
dt_pred = dt_classifier.predict(X_test_scaled)
dt_accuracy = accuracy_score(y_test, dt_pred)

# 2. Random Forest
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train_scaled, y_train)
rf_pred = rf_classifier.predict(X_test_scaled)
rf_accuracy = accuracy_score(y_test, rf_pred)

# Classification after Feature Selection

# 1. Decision Tree after RFE
dt_classifier_rfe = DecisionTreeClassifier(random_state=42)
dt_classifier_rfe.fit(X_train_rfe, y_train)
dt_pred_rfe = dt_classifier_rfe.predict(X_test_rfe)
dt_rfe_accuracy = accuracy_score(y_test, dt_pred_rfe)

# 2. Random Forest after SelectKBest
rf_classifier_kbest = RandomForestClassifier(random_state=42)
rf_classifier_kbest.fit(X_train_kbest, y_train)
rf_pred_kbest = rf_classifier_kbest.predict(X_test_kbest)
rf_kbest_accuracy = accuracy_score(y_test, rf_pred_kbest)

# Print results
print('Decision Tree Accuracy (Before Feature Selection):', dt_accuracy)
print('Random Forest Accuracy (Before Feature Selection):', rf_accuracy)
print('Decision Tree Accuracy (After RFE):', dt_rfe_accuracy)
print('Random Forest Accuracy (After SelectKBest):', rf_kbest_accuracy)
